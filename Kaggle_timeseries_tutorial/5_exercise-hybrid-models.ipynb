{"metadata":{"jupytext":{"cell_metadata_filter":"-all","formats":"ipynb,md"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Time Series](https://www.kaggle.com/learn/time-series) course.  You can reference the tutorial at [this link](https://www.kaggle.com/ryanholbrook/hybrid-models).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction #\n\nRun this cell to set everything up!","metadata":{}},{"cell_type":"code","source":"# Setup feedback system\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.time_series.ex5 import *\n\n# Setup notebook\nfrom pathlib import Path\nfrom learntools.time_series.style import *  # plot style settings\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import LabelEncoder\nfrom statsmodels.tsa.deterministic import DeterministicProcess\nfrom xgboost import XGBRegressor\n\n\ncomp_dir = Path('../input/store-sales-time-series-forecasting')\ndata_dir = Path(\"../input/ts-course-data\")\n\nstore_sales = pd.read_csv(\n    comp_dir / 'train.csv',\n    usecols=['store_nbr', 'family', 'date', 'sales', 'onpromotion'],\n    dtype={\n        'store_nbr': 'category',\n        'family': 'category',\n        'sales': 'float32',\n    },\n    parse_dates=['date'],\n    infer_datetime_format=True,\n)\nstore_sales['date'] = store_sales.date.dt.to_period('D')\nstore_sales = store_sales.set_index(['store_nbr', 'family', 'date']).sort_index()\n\nfamily_sales = (\n    store_sales\n    .groupby(['family', 'date'])\n    .mean()\n    .unstack('family')\n    .loc['2017']\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:01:48.408565Z","iopub.execute_input":"2022-03-11T10:01:48.408938Z","iopub.status.idle":"2022-03-11T10:01:55.609058Z","shell.execute_reply.started":"2022-03-11T10:01:48.408845Z","shell.execute_reply":"2022-03-11T10:01:55.608108Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\nIn the next two questions, you'll create a boosted hybrid for the *Store Sales* dataset by implementing a new Python class. Run this cell to create the initial class definition. You'll add `fit` and `predict` methods to give it a scikit-learn like interface.\n","metadata":{}},{"cell_type":"code","source":"# You'll add fit and predict methods to this minimal class\nclass BoostedHybrid:\n    def __init__(self, model_1, model_2):\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.y_columns = None  # store column names from fit method\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:01:55.610843Z","iopub.execute_input":"2022-03-11T10:01:55.611143Z","iopub.status.idle":"2022-03-11T10:01:55.616585Z","shell.execute_reply.started":"2022-03-11T10:01:55.611109Z","shell.execute_reply":"2022-03-11T10:01:55.615477Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# 1) Define fit method for boosted hybrid\n\nComplete the `fit` definition for the `BoostedHybrid` class. Refer back to steps 1 and 2 from the **Hybrid Forecasting with Residuals** section in the tutorial if you need.","metadata":{}},{"cell_type":"code","source":"def fit(self, X_1, X_2, y):\n    # First, train model 1 (linear regression) to learn the trend in the series (remember, trend is purely a function of time)\n    # YOUR CODE HERE: fit self.model_1\n    self.model_1.fit(X_1, y)\n\n    # Now make predictions using the trained model 1\n    y_fit = pd.DataFrame(\n        # YOUR CODE HERE: make predictions with self.model_1\n        self.model_1.predict(X_1),\n        index=X_1.index, columns=y.columns,\n    )\n\n    # YOUR CODE HERE: compute residuals\n    y_resid = y - y_fit\n    y_resid = y_resid.stack().squeeze() # wide to long\n\n    # The residuals are effectively random fluctuations, which we model with model 2\n    # YOUR CODE HERE: fit self.model_2 on residuals\n    self.model_2.fit(X_2, y_resid)\n\n    # Save column names for predict method\n    self.y_columns = y.columns\n    # Save data for question checking\n    self.y_fit = y_fit\n    self.y_resid = y_resid\n\n\n# Add method to class\nBoostedHybrid.fit = fit\n\n\n# Check your answer\nq_1.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:07:44.792116Z","iopub.execute_input":"2022-03-11T10:07:44.792616Z","iopub.status.idle":"2022-03-11T10:07:44.817750Z","shell.execute_reply.started":"2022-03-11T10:07:44.792577Z","shell.execute_reply":"2022-03-11T10:07:44.816685Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_1.hint()\n#q_1.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\n# 2) Define predict method for boosted hybrid\n\nNow define the `predict` method for the `BoostedHybrid` class. Refer back to step 3 from the **Hybrid Forecasting with Residuals** section in the tutorial if you need.","metadata":{}},{"cell_type":"code","source":"def predict(self, X_1, X_2):\n    # First, use model 1 (linear regression), to predict the trend\n    y_pred = pd.DataFrame(\n        # YOUR CODE HERE: predict with self.model_1\n        self.model_1.predict(X_1),\n        index=X_1.index, columns=self.y_columns,\n    )\n    y_pred = y_pred.stack().squeeze()  # wide to long\n\n    # Next, use model 2 (some decision tree or random forest) to predict the random variations\n    # Combine the predictions to get the overall predictions of the model\n    # YOUR CODE HERE: add self.model_2 predictions to y_pred\n    y_pred += self.model_2.predict(X_2)\n    \n    return y_pred.unstack()  # long to wide\n\n\n# Add method to class\nBoostedHybrid.predict = predict\n\n\n# Check your answer\nq_2.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:11:15.963954Z","iopub.execute_input":"2022-03-11T10:11:15.964276Z","iopub.status.idle":"2022-03-11T10:11:16.002559Z","shell.execute_reply.started":"2022-03-11T10:11:15.964246Z","shell.execute_reply":"2022-03-11T10:11:16.001507Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_2.hint()\n#q_2.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\nNow you're ready to use your new `BoostedHybrid` class to create a model for the *Store Sales* data. Run the next cell to set up the data for training.","metadata":{}},{"cell_type":"code","source":"# Target series\ny = family_sales.loc[:, 'sales']\n\n\n# X_1: Features for Linear Regression\ndp = DeterministicProcess(index=y.index, order=1)\nX_1 = dp.in_sample()\n\n\n# X_2: Features for XGBoost\nX_2 = family_sales.drop('sales', axis=1).stack()  # onpromotion feature\n\n# Label encoding for 'family'\nle = LabelEncoder()  # from sklearn.preprocessing\nX_2 = X_2.reset_index('family')\nX_2['family'] = le.fit_transform(X_2['family'])\n\n# Label encoding for seasonality\nX_2[\"day\"] = X_2.index.day  # values are day of the month","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:12:14.760466Z","iopub.execute_input":"2022-03-11T10:12:14.761521Z","iopub.status.idle":"2022-03-11T10:12:14.792123Z","shell.execute_reply.started":"2022-03-11T10:12:14.761465Z","shell.execute_reply":"2022-03-11T10:12:14.791407Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"X_1.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:15:49.388960Z","iopub.execute_input":"2022-03-11T10:15:49.389250Z","iopub.status.idle":"2022-03-11T10:15:49.398651Z","shell.execute_reply.started":"2022-03-11T10:15:49.389217Z","shell.execute_reply":"2022-03-11T10:15:49.397815Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:15:53.650654Z","iopub.execute_input":"2022-03-11T10:15:53.651452Z","iopub.status.idle":"2022-03-11T10:15:53.681337Z","shell.execute_reply.started":"2022-03-11T10:15:53.651401Z","shell.execute_reply":"2022-03-11T10:15:53.680513Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# 3) Train boosted hybrid\n\nCreate the hybrid model by initializing a `BoostedHybrid` class with `LinearRegression()` and `XGBRegressor()` instances.","metadata":{}},{"cell_type":"code","source":"# YOUR CODE HERE: Create LinearRegression + XGBRegressor hybrid with BoostedHybrid\nmodel = BoostedHybrid(LinearRegression(), XGBRegressor())\n\n# YOUR CODE HERE: Fit and predict\nmodel.fit(X_1, X_2, y)\ny_pred = model.predict(X_1, X_2)\n\ny_pred = y_pred.clip(0.0)\n\n\n# Check your answer\nq_3.check()","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:35:40.806424Z","iopub.execute_input":"2022-03-11T10:35:40.806698Z","iopub.status.idle":"2022-03-11T10:35:41.300015Z","shell.execute_reply.started":"2022-03-11T10:35:40.806665Z","shell.execute_reply":"2022-03-11T10:35:41.298955Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:24:14.739673Z","iopub.execute_input":"2022-03-11T10:24:14.740460Z","iopub.status.idle":"2022-03-11T10:24:14.750586Z","shell.execute_reply.started":"2022-03-11T10:24:14.740418Z","shell.execute_reply":"2022-03-11T10:24:14.749873Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\n#q_3.hint()\n#q_3.solution()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-------------------------------------------------------------------------------\n\nDepending on your problem, you might want to use other hybrid combinations than the linear regression + XGBoost hybrid you've created in the previous questions. Run the next cell to try other algorithms from scikit-learn.","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n# Model 1 (trend)\nfrom pyearth import Earth\nfrom sklearn.linear_model import ElasticNet, Lasso, Ridge\n\n# Model 2\nfrom sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.neural_network import MLPRegressor\n\n# Boosted Hybrid\n\n# YOUR CODE HERE: Try different combinations of the algorithms above\ndef compute_rmse(model_1, model_2):\n    model = BoostedHybrid(model_1,model_2)\n    model.fit(X_1,X_2,y)\n    y_pred = model.predict(X_1,X_2)\n    y_pred = y_pred.clip(0.0)\n    rmse = np.sqrt(np.sum((y - y_pred)**2))\n    return rmse\n\nlinreg_xgboost_rmse = compute_rmse(LinearRegression(), XGBRegressor())\nearth_xgboost_rmse = compute_rmse(Earth(), XGBRegressor())\nelasnet_xgboost_rmse = compute_rmse(ElasticNet(), XGBRegressor())\nlasso_xgboost_rmse = compute_rmse(Lasso(), XGBRegressor())\n\nlinreg_ranfor_rmse = compute_rmse(LinearRegression(), RandomForestRegressor())\nlinreg_knn_rmse = compute_rmse(LinearRegression(), KNeighborsRegressor())\nlinreg_mlp_rmse = compute_rmse(LinearRegression(), MLPRegressor())\nelasnet_ranfor_rmse = compute_rmse(ElasticNet(), RandomForestRegressor())\nelasnet_knn_rmse = compute_rmse(ElasticNet(), KNeighborsRegressor())\n\nrmses = {\n    'linreg_xgboost_rmse': np.mean(linreg_xgboost_rmse),\n    'earth_xgboost_rmse': np.mean(earth_xgboost_rmse),\n    'elasnet_xgboost_rmse': np.mean(elasnet_xgboost_rmse),\n    'lasso_xgboost_rmse': np.mean(lasso_xgboost_rmse),\n    'linreg_ranfor_rmse': np.mean(linreg_ranfor_rmse),\n    'linreg_knn_rmse': np.mean(linreg_knn_rmse),\n    'linreg_mlp_rmse': np.mean(linreg_mlp_rmse),\n    'elasnet_ranfor_rmse': np.mean(elasnet_ranfor_rmse),\n    'elasnet_knn_rmse': np.mean(elasnet_knn_rmse),\n}\n\nrmses\n","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:33:06.526161Z","iopub.execute_input":"2022-03-11T10:33:06.526478Z","iopub.status.idle":"2022-03-11T10:33:30.456952Z","shell.execute_reply.started":"2022-03-11T10:33:06.526444Z","shell.execute_reply":"2022-03-11T10:33:30.456082Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"The **best performance** averaged across the different time series was achieved using **ElasticNet** as the first model and **RandomForest** as the second. I.e. using ElasticNet to predict trend and RandomForest to predict residuals (random error).","metadata":{}},{"cell_type":"markdown","source":"These are just some suggestions. You might discover other algorithms you like in the scikit-learn [User Guide](https://scikit-learn.org/stable/supervised_learning.html).\n\nUse the code in this cell to see the predictions your hybrid makes.","metadata":{}},{"cell_type":"code","source":"# Use the models we found to be best: ElasticNet and RandomForest\nmodel = BoostedHybrid(ElasticNet(), RandomForestRegressor())\n\n# YOUR CODE HERE: Fit and predict\nmodel.fit(X_1, X_2, y)\ny_pred = model.predict(X_1, X_2)\n\ny_pred = y_pred.clip(0.0)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:37:18.329581Z","iopub.execute_input":"2022-03-11T10:37:18.330444Z","iopub.status.idle":"2022-03-11T10:37:20.093081Z","shell.execute_reply.started":"2022-03-11T10:37:18.330405Z","shell.execute_reply":"2022-03-11T10:37:20.092062Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"y_train, y_valid = y[:\"2017-07-01\"], y[\"2017-07-02\":]\nX1_train, X1_valid = X_1[: \"2017-07-01\"], X_1[\"2017-07-02\" :]\nX2_train, X2_valid = X_2.loc[:\"2017-07-01\"], X_2.loc[\"2017-07-02\":]\n\n# Some of the algorithms above do best with certain kinds of\n# preprocessing on the features (like standardization), but this is\n# just a demo.\nmodel.fit(X1_train, X2_train, y_train)\ny_fit = model.predict(X1_train, X2_train).clip(0.0)\ny_pred = model.predict(X1_valid, X2_valid).clip(0.0)\n\nfamilies = y.columns[0:6]\naxs = y.loc(axis=1)[families].plot(\n    subplots=True, sharex=True, figsize=(11, 9), **plot_params, alpha=0.5,\n)\n_ = y_fit.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C0', ax=axs)\n_ = y_pred.loc(axis=1)[families].plot(subplots=True, sharex=True, color='C3', ax=axs)\nfor ax, family in zip(axs, families):\n    ax.legend([])\n    ax.set_ylabel(family)","metadata":{"execution":{"iopub.status.busy":"2022-03-11T10:37:21.391553Z","iopub.execute_input":"2022-03-11T10:37:21.391863Z","iopub.status.idle":"2022-03-11T10:37:25.073240Z","shell.execute_reply.started":"2022-03-11T10:37:21.391829Z","shell.execute_reply":"2022-03-11T10:37:25.072249Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"# 4) Fit with different learning algorithms\n\nOnce you're ready to move on, run the next cell for credit on this question.","metadata":{}},{"cell_type":"code","source":"# View the solution (Run this cell to receive credit!)\nq_4.check()","metadata":{"lines_to_next_cell":2,"execution":{"iopub.status.busy":"2022-03-11T10:37:48.679718Z","iopub.execute_input":"2022-03-11T10:37:48.679970Z","iopub.status.idle":"2022-03-11T10:37:48.686830Z","shell.execute_reply.started":"2022-03-11T10:37:48.679942Z","shell.execute_reply":"2022-03-11T10:37:48.685967Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Keep Going #\n\n[**Convert any forecasting task**](https://www.kaggle.com/ryanholbrook/forecasting-with-machine-learning) to a machine learning problem with four ML forecasting strategies.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/time-series/discussion) to chat with other learners.*","metadata":{}}]}